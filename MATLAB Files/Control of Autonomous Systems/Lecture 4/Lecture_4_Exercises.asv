clc; clear; close all;
format compact

% Exercise 1, 2
disp('State Space Model')
A = [-0.4, 0, -0.01;
     1, 0, 0;
     -1.4, 9.8, -0.02]

B = [6.3;
     0;
     9.8]

% Since C (output) is not explicitly stated, we can assume
% that it is an identity matrix same dimensions as A
C = eye(size(A))

% Feedthrough is not defined, so this is a zero vector
% with the same size as B
D = zeros(size(B))

sys = ss(A, B, C, D);

e = eig(A)
poles = real(e);
% Check the real parts of the eigenvalues
disp(" ")
disp('Real parts of the eigenvalues: ')
disp(poles)
disp(" ")
if all(poles < 0)
    disp('The system is stable.');
elseif any(poles > 0)
    disp('The system is unstable.');
else
    disp('The system is marginally stable.');
end

% Exercise 3 solved in simulink

% Exercise 4

% Desired poles for the closed-loop system
disp(' ')
disp(' ')
disp('State Feedback Control')
lambda_cl = [-6, -3 + 2i, -3 - 2i]

K = place(A, B, lambda_cl)

A_cl = A - B * K

e_cl = eig(A_cl)
poles_cl = real(e_cl);
% Check the real parts of the eigenvalues
disp(" ")
disp('Real parts of the eigenvalues: ')
disp(poles_cl)
disp(" ")
if all(poles_cl < 0)
    disp('The system is stable.');
elseif any(poles_cl > 0)
    disp('The system is unstable.');
else
    disp('The system is marginally stable.');
end

u_star = 0;
x_star = [0,0,10]';

% Exercise 5
disp(' ')
disp(' ')
disp('LQR Control')
% Define Q and R matrices
% A common choice is to penalize all states equally
Q = C' * C
% Scalar R, penalizes the control effort
R = 1

% Compute the LQR gain matrix K
K_lqr = lqr(A, B, Q, R)

% Exercise 6 in Simulink

% Exercise 7
disp(' ')
disp(' ')
disp('Discretized LQR Control')

T = 0.01;
sample_period = 10*T;

sys_d = c2d(sys, sample_period, 'zoh')